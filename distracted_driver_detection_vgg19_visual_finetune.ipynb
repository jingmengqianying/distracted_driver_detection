{ "cells": [  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 侦测走神司机--基本模型VGG16\n",    "将图片在floyhub上训练好后，保存到本地，然后再在本地训练，VGG16是基准版本"   ]  },  {   "cell_type": "code",   "execution_count": 1,   "metadata": {    "collapsed": true   },   "outputs": [],   "source": [    "#导入相关的包\n",    "from urllib.request import urlretrieve \n",    "from os.path import isfile, isdir \n",    "from tqdm import tqdm \n",    "import zipfile \n",    "import csv\n",    "import os\n",    "import math  \n",    "import numpy as np  \n",    "import matplotlib.pyplot as plt     \n",    "from PIL import Image\n",    "from sklearn.model_selection import KFold\n",    "import pandas as pd\n",    "import shutil\n",    "import glob\n",    "import cv2"   ]  },  {   "cell_type": "code",   "execution_count": 5,   "metadata": {},   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "/output\n",      "/\n",      "all file is exits\n"     ]    }   ],   "source": [    "#获取相关的路径\n",    "cwd = os.getcwd()\n",    "print (cwd)\n",    "\n",    "input_mount = os.sep\n",    "print(input_mount)\n",    "\n",    "#图片数据路径\n",    "DRIVER_IMGS_PATH = os.path.join(input_mount,\"input\")\n",    "#图片CSV列表的数据 \n",    "DRIVER_IMGS_LIST_CVS_DATE_FILE =os.path.join(DRIVER_IMGS_PATH,\"driver_imgs_list.csv\")\n",    "#图片的数据目录 \n",    "DRIVER_IMGES_DATASET_FOLDER_PATH =DRIVER_IMGS_PATH\n",    "#图片训练集目录\n",    "TRAIN_DIR = os.path.join(DRIVER_IMGS_PATH,\"train\")\n",    "#图片测试集目录\n",    "TEST_DIR = os.path.join(DRIVER_IMGS_PATH,\"test\")\n",    "\n",    "csv_file = csv.reader(open(DRIVER_IMGS_LIST_CVS_DATE_FILE,'r'))\n",    "\n",    "print(\"all file is exits\")"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 加载数据集"   ]  },  {   "cell_type": "code",   "execution_count": null,   "metadata": {},   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "-------- loading train data\n",      "(20787, 224, 224, 3)\n",      "(20787, 10)\n",      "-------- loading valid data\n",      "(1637, 224, 224, 3)\n",      "(1637, 10)\n"     ]    }   ],   "source": [    "model_image_size = 224\n",    "print(\"加载训练集\")\n",    "X_train = list()\n",    "y_train = list()\n",    "train_subjects = ['p002','p012','p014','p015','p016','p021','p022','p024','p026','p035','p039','p041','p042','p045','p047','p049','p050',\n",    "                  'p051','p052','p056','p061','p064','p066','p072']\n",    "valid_subjects = ['p075','p081']\n",    "df = pd.read_csv(DRIVER_IMGS_LIST_CVS_DATE_FILE)\n",    "\n",    "for train_subject in train_subjects:\n",    "    df_train = df[(df[\"subject\"]==)]\n",    "    print(\"训练集驾驶员{}, 图片数量={}\".format(train_subject, len(df_train)))\n",    "    for index, row in df_train.iterrows():\n",    "        subpath = row[\"classname\"] + \"/\" + row[\"img\"]\n",    "        i = int( row[\"classname\"].replace('c',''))\n",    "        image_file = os.path.join(TRAIN_DIR,subpath)\n",    "        image = cv2.imread(image_file)\n",    "        X_train.append(cv2.resize(image, (model_image_size, model_image_size)))\n",    "        label = np.zeros(10, dtype=np.uint8)\n",    "        label[i]=1\n",    "        y_train.append(label)\n",    "X_train = np.array(X_train)\n",    "y_train = np.array(y_train)  \n",    "\n",    "print(X_train.shape)\n",    "print(y_train.shape)\n",    "\n",    "print(\"加载验证集\")\n",    "X_valid = list()\n",    "y_valid = list()\n",    "\n",    "for valid_subject in valid_subjects:\n",    "    df_valid = df[(df[\"subject\"]==valid_subject)]\n",    "    print(\"验证集驾驶员{}, 图片数量={}\".format(train_subject, len(df_train)))\n",    "    for index, row in df_valid.iterrows():\n",    "        subpath = row[\"classname\"] + \"/\" + row[\"img\"]\n",    "        i = int( row[\"classname\"].replace('c',''))\n",    "        image_file = os.path.join(TRAIN_DIR,subpath)\n",    "        image = cv2.imread(image_file)\n",    "        X_valid.append(cv2.resize(image, (model_image_size, model_image_size)))\n",    "        label = np.zeros(10, dtype=np.uint8)\n",    "        label[i]=1\n",    "        y_valid.append(label)\n",    "        \n",    "X_valid = np.array(X_valid)\n",    "y_valid = np.array(y_valid)\n",    "\n",    "print(X_valid.shape)\n",    "print(y_valid.shape)"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 构建模型"   ]  },  {   "cell_type": "code",   "execution_count": 7,   "metadata": {},   "outputs": [    {     "name": "stderr",     "output_type": "stream",     "text": [      "Using TensorFlow backend.\n"     ]    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",      "58580992/58889256 [============================>.] - ETA: 0sdone\n"     ]    }   ],   "source": [    "from keras.models import *\n",    "from keras.optimizers import *\n",    "from keras.layers import *\n",    "from keras.applications import *\n",    "from keras.preprocessing.image import *\n",    "\n",    "base_model = VGG16(input_tensor=Input((model_image_size, model_image_size, 3)), weights='imagenet', include_top=False)\n",    "\n",    "for layers in base_model.layers:\n",    "    layers.trainable = False\n",    "\n",    "x = GlobalAveragePooling2D()(base_model.output)\n",    "x = Dropout(0.25)(x)\n",    "x = Dense(10, activation='softmax')(x)\n",    "model = Model(base_model.input, x)\n",    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",    "\n",    "#     model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",    "print(\"构建模型完成\")"   ]  },  {   "cell_type": "markdown",   "metadata": {},   "source": [    "## 训练模型"   ]  },  {   "cell_type": "code",   "execution_count": 8,   "metadata": {},   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "Train on 20787 samples, validate on 1637 samples\n",      "Epoch 1/10\n",      "20787/20787 [==============================] - 436s - loss: 0.7211 - acc: 0.8593 - val_loss: 0.4657 - val_acc: 0.8861\n",      "Epoch 2/10\n",      "20787/20787 [==============================] - 435s - loss: 0.3151 - acc: 0.9110 - val_loss: 0.4484 - val_acc: 0.8932\n",      "Epoch 3/10\n",      "20787/20787 [==============================] - 435s - loss: 0.1830 - acc: 0.9394 - val_loss: 0.3360 - val_acc: 0.9016\n",      "Epoch 4/10\n",      "20787/20787 [==============================] - 435s - loss: 0.1321 - acc: 0.9540 - val_loss: 0.3498 - val_acc: 0.9009\n",      "Epoch 5/10\n",      "20787/20787 [==============================] - 436s - loss: 0.1064 - acc: 0.9611 - val_loss: 0.3552 - val_acc: 0.9016\n",      "Epoch 6/10\n",      "20787/20787 [==============================] - 434s - loss: 0.0956 - acc: 0.9649 - val_loss: 0.2956 - val_acc: 0.9062\n",      "Epoch 7/10\n",      "20787/20787 [==============================] - 435s - loss: 0.0858 - acc: 0.9681 - val_loss: 0.3288 - val_acc: 0.9022\n",      "Epoch 8/10\n",      "20787/20787 [==============================] - 435s - loss: 0.0804 - acc: 0.9710 - val_loss: 0.3464 - val_acc: 0.8973\n",      "Epoch 9/10\n",      "20787/20787 [==============================] - 435s - loss: 0.0768 - acc: 0.9721 - val_loss: 0.3451 - val_acc: 0.9041\n",      "Epoch 10/10\n",      "20787/20787 [==============================] - 435s - loss: 0.0763 - acc: 0.9715 - val_loss: 0.2913 - val_acc: 0.9052\n"     ]    }   ],   "source": [    "model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_valid, y_valid))\n",    "#图片测试集目录\n",    "Model_DIR = os.path.join(cwd,\"vgg16-mymodel.h5\")\n",    "model.save(Model_DIR)"   ]  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 3   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython3",   "version": "3.5.3"  } }, "nbformat": 4, "nbformat_minor": 2}
